---
layout: single
permalink: /
author_profile: true
sitemap: false
redirect_from: 
  - /about/
  - /about.html
---

I am a final year PhD student at the [University of Würzburg](https://www.informatik.uni-wuerzburg.de/nlp/wuenlp/), Germany, and advised by [Goran Glavaš](https://sites.google.com/view/goranglavas) (University of Würzburg) and [Ivan Vulić](https://sites.google.com/site/ivanvulic/) (University of Cambridge). I am interested in robust and scalable cross-lingual transfer in the field of Natural Language Processing. Before that, I obtained my B.Sc. in Finance and interned at Goldman Sachs in London. Next to my research, I sometimes contribute to open source projects like [telescope.nvim](https://github.com/nvim-telescope/telescope.nvim). You can find more info on my [CV](https://fdschmidt93.github.io/files/240917_CV_FDS.pdf).

## News

<table class="twoColumnTable">
    <tbody>
        <tr>
            <td class="left-column">September, 2024</td>
            <td class="right-column">I have started my 3 months research internship on massively multilingual spoken language understanding with <a href="https://dadelani.github.io/">David Adelani</a> at <a href="https://mila.quebec/en">Mila</a>, Montreal.</td> 
        </tr>
        <tr>
            <td class="left-column">June, 2024</td>
            <td class="right-column">Our paper <a href="https://arxiv.org/abs/2406.12739">Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages</a> is out! This was joint work with <a href="https://scholar.google.com/citations?user=efKKfygAAAAJ&hl=en">Philipp Borchert</a>, <a href="https://sites.google.com/site/ivanvulic/">Ivan Vulić</a>, and <a href="https://sites.google.com/view/goranglavas">Goran Glavaš</a> during my research visit in Cambridge.</td>
        </tr>
        <tr>
            <td class="left-column">May, 2024</td>
            <td class="right-column">I will be doing a research visit in the <a href="https://ltl.mmll.cam.ac.uk/">Language Technology Lab</a> at the <a href="https://www.cam.ac.uk/">University of Cambridge</a> hosted by <a href="https://sites.google.com/site/ivanvulic/">Ivan Vulić</a>!</td>
        </tr>
        <tr>
            <td class="left-column">Jan, 2024</td>
            <td class="right-column">I started my 4-month internship at NEC Laboratories Europe with <a href="https://chiachienhung.github.io/">Chia-Chien Hung</a> and <a href="https://carolinlawrence.github.io/">Carolin Lawrence.</a></td>
        </tr>
        <tr>
            <td class="left-column">Oct, 2023</td>
            <td class="right-column">Our paper "One For All & All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer" was accepted to Findings of EMNLP!</td>
        </tr>
        <tr>
            <td class="left-column">Sep, 2023</td>
            <td class="right-column">I gave an invited talk about my work on <a href="https://fdschmidt93.github.io/files/xlt_invited-talk@uds.pdf"><b>robust and scalable cross-lingual transfer</b></a> at the <a href="https://www.uni-saarland.de/en/department/lst.html">Language Science and Technology department of Uni Saarland</a>.</td>
        </tr>
    </tbody>
</table>


## Publications

<table>
    <tr> 
        <td><b>Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages</b><br>
        <u>Fabian David Schmidt</u>, Ivan Vulić, Goran Glavaš.<br>
        <i>Findings of the 2024 Conference on Empirical Methods in Natural Language Processing</i><br>
        <div class="conf_button"><b>EMNLP</b></div>&nbsp;<div class="paper_button"><b>LONG</b></div>
        </td>
    </tr>
    <tr> 
        <td><b>One For All & All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer</b><br>
        <u>Fabian David Schmidt</u>, Ivan Vulić, Goran Glavaš.<br>
        <i>Findings of the 2023 Conference on Empirical Methods in Natural Language Processing</i><br>
        <div class="conf_button"><b>EMNLP</b></div>&nbsp;<div class="paper_button"><b>SHORT</b></div>
        </td>
    </tr>
    <tr> 
        <td><a href="https://aclanthology.org/2023.acl-long.314/"><b>Free Lunch: Robust Cross-Lingual Transfer via Model Checkpoint Averaging</b></a><br>
        <u>Fabian David Schmidt</u>, Ivan Vulić, Goran Glavaš.<br>
        <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</i><br>
        <div class="conf_button"><b>ACL</b></div>&nbsp;<div class="paper_button"><b>LONG</b></div>
        </td>
    </tr>
    <tr> 
        <td><a href="https://aclanthology.org/2022.emnlp-main.736/"><b>Don’t Stop Fine-Tuning: On Training Regimes for Few-Shot Cross-Lingual Transfer with Multilingual Language Models</b></a><br>
        <u>Fabian David Schmidt</u>, Ivan Vulić, Goran Glavaš.<br>
        <i>Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</i><br>
        <div class="conf_button"><b>EMNLP</b></div>&nbsp;<div class="paper_button"><b>LONG</b></div>
        </td>
    </tr>
    <tr> 
        <td><a href="https://aclanthology.org/2022.emnlp-main.740/"><b> SLICER: Sliced Fine-Tuning for Low-Resource Cross-Lingual Transfer for Named Entity Recognition</b></a><br>
        <u>Fabian David Schmidt</u>, Ivan Vulić, Goran Glavaš.<br>
        <i>Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</i><br>
        <div class="conf_button"><b>EMNLP</b></div>&nbsp;<div class="paper_button"><b>SHORT</b></div>
        </td>
    </tr>
    <tr> 
        <td><a href="https://aclanthology.org/D19-3034/"><b>SEAGLE: A Platform for Comparative Evaluation of Semantic Encoders for Information Retrieval</b></a><br>
        <u>Fabian David Schmidt</u>, Markus Dietsche, Simone Paolo Ponzetto, Goran Glavaš.<br>
        <i>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</i><br>
        <div class="conf_button"><b>EMNLP</b></div>&nbsp;<div class="paper_button"><b>DEMO</b></div>
        </td>
    </tr>
</table>

